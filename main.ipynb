{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ba126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2889a2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Epoch 1/30\n",
      "300/300 - 3s - loss: 0.3057 - accuracy: 0.9135 - val_loss: 0.1584 - val_accuracy: 0.9553 - 3s/epoch - 11ms/step\n",
      "Epoch 2/30\n",
      "300/300 - 3s - loss: 0.1259 - accuracy: 0.9638 - val_loss: 0.1060 - val_accuracy: 0.9677 - 3s/epoch - 10ms/step\n",
      "Epoch 3/30\n",
      "300/300 - 3s - loss: 0.0837 - accuracy: 0.9757 - val_loss: 0.0843 - val_accuracy: 0.9740 - 3s/epoch - 10ms/step\n",
      "Epoch 4/30\n",
      "300/300 - 3s - loss: 0.0598 - accuracy: 0.9829 - val_loss: 0.0709 - val_accuracy: 0.9791 - 3s/epoch - 10ms/step\n",
      "Epoch 5/30\n",
      "300/300 - 2s - loss: 0.0448 - accuracy: 0.9874 - val_loss: 0.0726 - val_accuracy: 0.9779 - 2s/epoch - 8ms/step\n",
      "Epoch 6/30\n",
      "300/300 - 3s - loss: 0.0343 - accuracy: 0.9904 - val_loss: 0.0677 - val_accuracy: 0.9776 - 3s/epoch - 9ms/step\n",
      "Epoch 7/30\n",
      "300/300 - 3s - loss: 0.0263 - accuracy: 0.9929 - val_loss: 0.0635 - val_accuracy: 0.9785 - 3s/epoch - 9ms/step\n",
      "Epoch 8/30\n",
      "300/300 - 3s - loss: 0.0210 - accuracy: 0.9945 - val_loss: 0.0649 - val_accuracy: 0.9806 - 3s/epoch - 9ms/step\n",
      "Epoch 9/30\n",
      "300/300 - 3s - loss: 0.0157 - accuracy: 0.9963 - val_loss: 0.0606 - val_accuracy: 0.9802 - 3s/epoch - 10ms/step\n",
      "Epoch 10/30\n",
      "300/300 - 3s - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.0647 - val_accuracy: 0.9787 - 3s/epoch - 10ms/step\n",
      "Epoch 11/30\n",
      "300/300 - 3s - loss: 0.0098 - accuracy: 0.9980 - val_loss: 0.0637 - val_accuracy: 0.9817 - 3s/epoch - 10ms/step\n",
      "Epoch 12/30\n",
      "300/300 - 3s - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.0653 - val_accuracy: 0.9803 - 3s/epoch - 10ms/step\n",
      "Epoch 13/30\n",
      "300/300 - 3s - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0650 - val_accuracy: 0.9814 - 3s/epoch - 9ms/step\n",
      "Epoch 14/30\n",
      "300/300 - 3s - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.0609 - val_accuracy: 0.9827 - 3s/epoch - 9ms/step\n",
      "Epoch 15/30\n",
      "300/300 - 2s - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.0640 - val_accuracy: 0.9812 - 2s/epoch - 6ms/step\n",
      "Epoch 16/30\n",
      "300/300 - 2s - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.0654 - val_accuracy: 0.9810 - 2s/epoch - 8ms/step\n",
      "Epoch 17/30\n",
      "300/300 - 3s - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0631 - val_accuracy: 0.9835 - 3s/epoch - 8ms/step\n",
      "Epoch 18/30\n",
      "300/300 - 3s - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.0643 - val_accuracy: 0.9826 - 3s/epoch - 9ms/step\n",
      "Epoch 19/30\n",
      "300/300 - 3s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 0.9832 - 3s/epoch - 10ms/step\n",
      "Epoch 20/30\n",
      "300/300 - 3s - loss: 7.4663e-04 - accuracy: 1.0000 - val_loss: 0.0624 - val_accuracy: 0.9831 - 3s/epoch - 10ms/step\n",
      "Epoch 21/30\n",
      "300/300 - 3s - loss: 5.9961e-04 - accuracy: 1.0000 - val_loss: 0.0645 - val_accuracy: 0.9828 - 3s/epoch - 10ms/step\n",
      "Epoch 22/30\n",
      "300/300 - 3s - loss: 5.2277e-04 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 0.9834 - 3s/epoch - 9ms/step\n",
      "Epoch 23/30\n",
      "300/300 - 3s - loss: 4.2354e-04 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9839 - 3s/epoch - 9ms/step\n",
      "Epoch 24/30\n",
      "300/300 - 3s - loss: 3.7432e-04 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9829 - 3s/epoch - 10ms/step\n",
      "Epoch 25/30\n",
      "300/300 - 3s - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.0858 - val_accuracy: 0.9775 - 3s/epoch - 10ms/step\n",
      "Epoch 26/30\n",
      "300/300 - 3s - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0739 - val_accuracy: 0.9814 - 3s/epoch - 9ms/step\n",
      "Epoch 27/30\n",
      "300/300 - 3s - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0697 - val_accuracy: 0.9839 - 3s/epoch - 10ms/step\n",
      "Epoch 28/30\n",
      "300/300 - 3s - loss: 8.7878e-04 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9832 - 3s/epoch - 9ms/step\n",
      "Epoch 29/30\n",
      "300/300 - 3s - loss: 4.3422e-04 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 0.9843 - 3s/epoch - 9ms/step\n",
      "Epoch 30/30\n",
      "300/300 - 3s - loss: 2.7288e-04 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9843 - 3s/epoch - 9ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2590e-04 - accuracy: 1.0000\n",
      "\n",
      "Accuracy: 1.0000\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0679 - accuracy: 0.9843\n",
      "\n",
      "Val_Accuracy: 0.9843\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝에 필요한 케라스 함수 호출\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# 필요 라이브러리 호출\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "# 데이터 셋 호출\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# 실행 시마다 같은 결과값 도출을 위한 시드 설정\n",
    "#numpy.random.seed(0)\n",
    "#tf.random.set_seed(0)\n",
    "\n",
    "\n",
    "\n",
    "# 데이터를 불러와서 각 변수에 저장\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 학습에 적합한 형태로 데이터 가공\n",
    "X_train = X_train.reshape(X_train.shape[0], 784).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 784).astype('float32') / 255\n",
    "print(X_train)\n",
    "\n",
    "# 클래스를 학습에 이용하기 위해 데이터 가공\n",
    "Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_test, 10)\n",
    "\n",
    "# 딥러닝 모델 구조 설정(2개층, 512개의 뉴런 연결, 10개 클래스 출력 뉴런, 784개 픽셀 input 값, relu와 softmax 활성화 함수 이용)\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=784, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# 딥러닝 구조 설정(loss 옵션을 다중 클래스에 적합한 categorical_crossentropy, 옵티마이저는 adam 설정)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 실행(X_test, Y_test로 검증, 200개씩 30번 학습)\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30, batch_size=200, verbose=2)\n",
    "\n",
    "# 학습 정확도, 검증 정확도 출력\n",
    "print('\\nAccuracy: {:.4f}'.format(model.evaluate(X_train, Y_train)[1]))\n",
    "print('\\nVal_Accuracy: {:.4f}'.format(model.evaluate(X_test, Y_test)[1]))\n",
    "\n",
    "# 모델 저장\n",
    "model.save('handwriting_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f221c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "model.save('handwriting_model.h5')\n",
    "\n",
    "# 모델 로드\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('handwriting_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30afc049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n",
      "[[0 0 0 0 0 1 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 딥러닝에 필요한 케라스 함수 호출\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# 필요 라이브러리 호출(PIL은 이미지파일 처리위함)\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# test.png는 그림판에서 붓으로 숫자 8을 그린 이미지 파일\n",
    "# test.png 파일 열어서 L(256단계 흑백이미지)로 변환\n",
    "img = Image.open(\"test_77.png\").convert(\"L\")\n",
    "\n",
    "# 이미지를 784개 흑백 픽셀로 사이즈 변환\n",
    "img = np.resize(img, (1, 784))\n",
    "\n",
    "# 데이터를 모델에 적용할 수 있도록 가공\n",
    "test_data = ((np.array(img) / 255) - 1) * -1\n",
    "\n",
    "# 모델 불러오기\n",
    "model = load_model('handwriting_model.h5')\n",
    "\n",
    "# 클래스 예측 함수에 가공된 테스트 데이터 넣어 결과 도출\n",
    "res =(model.predict(test_data) > 0.5).astype(\"int32\")\n",
    "\n",
    "print(res)\n",
    "np.argmax(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cb94e05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAADiklEQVR4nO2az0syQRjHdVE3MkQCMVkKuxUbhSmE1SGJLh3q4CXo1h/Qj0P/QhBEhzxEBB26dAgPHaK6ZMeKwH4QSQhZUJGJNahZ4e68h5eG6e2t1p7BIZjvaUZnvs/zWZ6dmV01Y4xNv1kS7wSgEgC8JQB4SwDwlgDgLQHAWwKAtwQAbwkA3hIAb+rq6jKXr1QqBYzLBgBjfHJywsSqXLEBSCaTuVyOiVW5YgNweHjIxOcHsjBxoQFaWloikYjBiXV1dcDQ7AG6u7t7enqY2BoR+xIKBAJMPA2KAcD9/f3NzQ3p+v1+uKdxMQCIx+OkLcuyqqpwT+NiAEDXT1tbm9VqhXsaF2OACtePiTlAhe9gE3wZLRaL5+fnpOv3+zVN297eXltb29/fv7i4QAg5HA632x0IBPr7+wcHB6uqqoBB3wnDtLe3R6ysVmskEqmvr/8inKIoi4uLuq4D4xJBARYWFn5w1cLhcD6fZwIALaHPTkGyLCuK4na7EUKpVOrp6Yn+NhqNXl9fx2IxBuUEvADBYPAfw2AwuLKyUiwWyZiXl5etra2P54vh4WFgdAwsIU3T7HY7SUiSpJmZGU3TPhs/OzsrSe/WvfX1dUgCGAiQz+cnJyfD4bDP53M6nXNzc99OmZqaogF8Ph8kAQy/icuVruutra00w/HxMcSw0g/1ZrN5YmKC/mRzcxNiyOGtRF9fH90FPs1xAFAUpaamhnTT6TTEjc97odraWtJGCEGs+AAUCgXSdjqdECvQTvz8/Jx+kyzLvb29Rma9vr4+PDyQrsvlguQAAmhvbz87O/vbbmhouLy8NDJrd3dX13XSBT5CgEqIXtGvrq4SiYSRWdFolO5CX2FANpH5+Xnaanx8/Nspt7e31dXVZIqqqpAEMHAnzmazsiyTbGw22+np6RfjS6VSKBSimZeWliAJYPhRYmxsjE7I6/Umk8n/jiwUCgMDA/Tgjo6OUqkETAAKgBBSFIVOy+FwTE9PZzIZMiaXyy0vL3u9XnqY3W5PJBLA6JjJYe7o6OjjWi5JUlNTU2dnZ3NzM11mpNg2NjbgoTGr0+jBwUFjY+NXawUll8sVi8WYxMUMj9MIodHRUXqF+SiLxTIyMnJ3d8cqKMbYjJn+azGbza6uru7s7MTj8Uwm8/j4aLPZPB6PqqqhUGhoaMjj8TAMZzKZGANUXuJXSt4SALwlAHhLAPDWH/vXgZW7WktYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# 텍스트와 이미지 크기, 폰트 설정\n",
    "text = str(np.argmax(res))\n",
    "image_size = (64, 64)\n",
    "font_size = 50\n",
    "font = ImageFont.truetype('ARIAL.TTF', font_size)\n",
    "\n",
    "# 이미지 생성\n",
    "image = Image.new(\"RGB\", image_size, color=(255, 255, 255))\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "\n",
    "# 텍스트 위치 계산\n",
    "text_size = draw.textsize(text, font=font)\n",
    "text_position = ((image_size[0] - text_size[0]) / 2, (image_size[1] - text_size[1]) / 2)\n",
    "\n",
    "# 이미지에 텍스트 추가\n",
    "draw.text(text_position, text, font=font, fill=(0, 0, 0))\n",
    "\n",
    "# 이미지 저장\n",
    "image.save(\"text_image.png\")\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename='text_image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d414e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a98b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcdbdad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
